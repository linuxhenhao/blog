categories: network,linux
tags: congestion control,network,tcp
keywords: bbr,kcp,cdg,Delay Gradient,none congestion related loss
title: Tcp_congestion_control BBR KCP CDG非拥塞丢包情景对比
date: 2017-12-09 10:04:36+08:00

题目很可怕，然而实际上主要是要通过论文分析cdg，然后根据bbr和kcp介绍的特性判断一下哪种
拥塞控制算法最适合有一定非拥塞导致的丢包的网络环境（连通vps常见场景）。
<!--more-->
## 0.TCP一般拥塞控制逻辑
普通的tcp有三个状态，分别是`slow start`、`congestion avoidence`和`fast recovery`。
连接建立时通过`slow start`每个RTT指数级的增长cwnd，当$cwnd\ge{sshthresh}$时，进入
`congestion avoidence`模式，每个RTT将cwnd增大1，进入线性增长阶段。直到遇到丢包，这是由
于包一直在发送，实际网络中很少发生堵死的情况，因此后面的包的ack会返回，产生`dumpack`，由
此进入`fast recovery`模式，将丢包时的cwnd减半，设置为新的ssthresh值，cwnd=ssthresh+3MSS，
减小发送窗口，并且由于多收到了三个`dumpack`因此在发送窗口减半之后增加三个MSS大小。
重发丢失的包，等待该包的ack，在此期间新到的ack因为重发的包未到接收端，因此都是被重发包的dumpack，为了保持
正常的发包速率，每收到一个包的`ack`就将cwnd增加1，这样就可以保持网络速率不变。

细心的观众会发现，这不就是`slow start`的指数增长模式吗？有点像，其实不然，cwnd的值变化规律
确实一样，但是由于拖油瓶`重发包`的存在，cwnd的一端作为滑动窗口滑不起来，如果在收到ack后不变
cwnd，那么由于最老的未接受的包卡住，将会在一段时间内没有新的包可以发出，发生断流。

但是这样作，在收到重发包后接收端很可能由于`cumulative ack`机制发送一个隔了很远之后的ack，
过来，造成cwnd大跃进，发送速率会突增。因此实际情况是，当`fast recovery`模式下收到非`dumpack`

## 1.BBR
bbr分别探测带宽和min_RTT，来实现对带宽和真实延迟的探测，从而得到正确的发送窗口。

bbr有几个特点，其中我认为对于具备较高非拥塞导致的丢包环境中重要的特性是，即便在recovery
模式下，bbr除了第一个RTT时间内保持发包速率不变，从第二个Round开始采用slow start增加cwnd，
这能够使数据传输在遇到这种丢包导致频繁进入recovery模式时仍然能够迅速的

## 2. KCP
kcp采用激进的重传策略，在浪费一定带宽的情况下能够有效减小网络延迟。在一些对延迟要求高的
网络游戏上很好用。同时由于它的激进重传策略，对于有比较明显的丢包（1%）的情况下，throughput
比传统的tcp拥塞控制，比如cubic效果有明显的提升。但是话说回来，用来连接vps的话，kcp目前可用
的也就是`kcptun`，需要服务端和客户端均运行软件来实现，相比与内建的tcp拥塞控制算法来说通用
易用性明显较差。

2\.1 kcp的特性分析
先来看看[kcp特性介绍](1)
    1. RTO不翻倍
    2. 选择性重传
    3. 快速重传
    4. 非延迟ACK
    5. 非退让流控
对于1，在tcp的运行过程当中，只有发生timeout的时候才会对timeout的阀值进行调整，对于一条
正常运行的tcp连接来说，由于后续的包一直在发送当中，异常丢包后通常是会触发由于`duplicate ACK`
而进入`quick restart`模式，timeout的值影响很小（没有实际的证据，但是应该如此）。

对于2，各位观众，tcp冤啊，普通的tcp拥塞控制都是处于一种`cumulative ACK+选择性重传`的半
选择性重传的模式下的，并非KCP页面上所说的全部重传。`cumulative ACK`累计ACK：指到目前位置正常收到
的包序列号的上限+1。比如现在发送除了5-20共16个包，然后5丢了。接收端第一时间收到的是6-20的
包，由于采用累计ACK，出现乱序包时发送最近成功接受的ACK，也就是4+1=5的ACK，收到6、7、8后，
就已经发送了3次在需要5的ACK，触发快速重传.

快速重传的重发只重发一个包，这是半选择性重传的关键。重发到达后，由于5-20的包均收到，直接发送
需求21的ACK，这样发送端并不需要在5丢失时重发5-20所有的包。

这样的半选择性重传可以减少带宽的浪费，但是对于单条连接的响应时间和带宽利用并不友好。现象上述
场景，如果5-20的包跳着掉，即5、7、9、11...，这样由于ACK包的累计特性，对于包5的`dumplicate ACK`
导致5的重传，接收到5后，7的快速重传触发...。这样下去中间有多少个RTT才能到包20被接收端真正完成？
如果ACK是包含包序号信息，那么发送端就可以明确知道哪些包收到了，哪些包没收到，快速重传时直接
一次重传5、7、9，将明显提高窗口移动速度即发包速率，提高响应时间。

因此，kcp的选择性重传相比一般的TCP拥塞控制是有明确优势的。但是，很遗憾的是，这种ACK的支持必须
在服务端和客户端都做，对于普通服务器场景不太方便，但是对于有客户端的场景还是很不错的！

对于3，在2里面说过了，tcp本身就有快速重传。

对于4，普通的tcp运行过程，由于采用`累计ACK`的方式，为了减少ACK的发送，在收到正常按序到达的包
时不立即发送ACK，而是等待一段时间，比如500ms，发送当前正常到达的最大的序号的ACK。这样其实就是
一个响应时间与带宽利用率的tradeoff。tcp带有一个选项tcp_nodelay用来关闭这个特性，因此该特性
普通tcp本身具备。

对于5，采用接收缓存大小和发送缓存大小来控制发包。完全牺牲公平性，对丢包不做任何反应。其它的
tcp流在遇到丢包时直接把cwnd减半，而kcp继续保持发送速率，这样确实能够抢占更多的带宽，但是如果
更多的人都这样干，那就是把路由堵死大家都别玩了的干伙。

## cbg——Delay Gradient Congestion Control
对于普通的tcp工作模式，采用丢包作为拥塞探测的特征，周期性的流量涨落故意填满路由缓存来探
测带宽上限，导致tcp流量的锯齿状以及路由缓存常常被填满满的问题。很多新的方法被提出，主要是
改变拥塞探测特征，采用RTT的变化来探测拥塞情况以达到抹平tcp流量的锯齿以及使路由器buffer工作
在不满的状态。 由于不采用丢包作为网络拥塞的特征，__该类型的拥塞控制算法能在包含非拥塞导致
的丢包的网络连接上更好的工作__。一下所有内容均来自`NETWORKING 2011: 10th International IFIP TC 6 Networking Conference, Valencia, Spain, May 9-13, 2011, Proceedings, Part II, 381-399`

### RTT梯度的计算方法
RTT用$\tau$表示，由于RTT会有一些噪音，并非全由路由缓存的变化导致，因此CDG采用了最大
和最小RTT差以及`moving average`的方式减少噪音的影响。

具体来说，用一段时间内的RTT最小值$\tau_{min}$和RTT最大值$\tau\_{max}$作为该段
时间的特征值，然后用相邻两段时间的最大与最大、最小与最小的差作为梯度，较少噪音影响。用
$$g_{min}=\tau_{min, n}-\tau_{min, n-1}$$
$$g_{max}=\tau_{max, n}-\tau_{max, n-1}$$
两个梯度，最大延迟以及最小延迟的梯度二者的变化特征来判断拥塞以及路由缓存情况。

CDG还采用了`moving average`的方式平滑数据减小噪音，所谓的`moving average`其实就是只算
最近的一定数量的平均值，假定只算a个数据的平均值
$$\bar{g}_n=\frac{\sum_{i=n-a}^{n}g_{i}}{a}$$
实际使用中采用递推关系式：
$$\bar{g}_n-\bar{g}_{n-1}=\frac{\sum_{i=n-a}^{n}g_{i}-\sum_{i=n-a-1}^{n-1}g_{i}}{a}
=\frac{g_{n}-g_{n-a-1}}{a}$$
用该公式计算得到\\(g_{max}、g_{min}\\)的平均值，然后用来作为拥塞情况和路由缓存情况的判据。

### 梯度变化如何反应拥塞和缓存情况
这个就简单了，一张图解决问题![cdg-cc](/images/post-images/cdg-cc.png)

随着发送速率的增大，路由器缓存填充成都逐渐增大，延迟逐渐升高，直到缓存填满，继续增大发送速率
延迟不再发生变化，此时探测到拥塞了，开始减小发送窗口，路由器缓存减小，因此延迟随之减小，直到
继续减小发送速率而延迟不再变化，说明缓存清空。

对应的梯度也就是斜率变化在右图，当\\(g_{max}、g_{min}\\)先后从正变为0，说明填满缓存;
\\(g_{min}、g_{max}\\)先后由负变为0，说明缓存清空。

只有在缓存填满情况下的丢包才被认为是真正的由于拥塞导致的丢包，才需要采取措施减小发送窗口。
而其他情况下的丢包，在CDG算法当中，为了和普通的tcp共存增强公平性，采用概率性减小窗口。由于
采用延迟时间来判断拥塞情况，而不是故意造成路由缓存爆炸，该算法可以使tcp的流量更为平滑。

### CDG的具体行为
cdg同样具有`启动`-`congestion avoidence`-`fast recovery`这三个模式。

#### 1. 启动
启动和`slow start`相似，采用hybrid模式，每收到一个包就将cwnd+1，采用两种方式同时判断
拥塞发生。一种是丢包，这就与普通的tcp一致。另一种是每个RTT进行一次判断，如果达到backoff
条件，那么也进入`congestion avoidence`模式。backoff条件在之后的`congestion avoidence`
模式中详细解释。

#### 2. congestion avoidence
对于`congestion avoidence`和`fast recovery`的处理是CDG算法的主要不同。
$$ w_{i+1}=
  \begin{cases}
  w_{i}\beta &  X<P_{backoff}\land \bar{g}_n>0 \\
  w_{i}      &  otherwiser \\
  \end{cases}
  $$

在进入`congestion avoidence`模式后，只要$\bar{g}>0$就认为发包超过了路由的处理能力，导致
缓存增长，从而延迟增大，此时就进行概率性的减小发送速率。其中的$\beta$为缩小因子，论文中给出
为0.7。X为[0, 1]之间的随机数，由$P_{backoff}$给出减小发送的概率。具体公式为
$$P_{backoff}=1-e^{-\frac{\bar{g}}{G}}$$

$\bar{g}\text{为平均梯度，}G\text{参考因子}$

## 简单的测试
主要用途在于服务端向客户端发送数据，能够真正有效的利用实际带宽而不是被非拥塞导致的丢包大大
限制带宽利用率，因此做一个简单的测试.使用wget单线程从服务端下载一个相同大小的文件，对比cdg
和bbr

名称| 速率
----|----
bbr | \\(0.91Mps\\)
cdg | \\(60kps/890kps^*\\)

\\(^*\\)参数调节很重要，需要对cdg的过程理解之后进行调参，默认参数甚至比cubic算法速率更低。


[1]:https://github.com/skywind3000/kcp
